# 1236. Web Crawler

[https://leetcode.com/problems/web-crawler/description/](https://leetcode.com/problems/web-crawler/description/)

## solution

```python
class Solution:
    def crawl(self, startUrl: str, htmlParser: 'HtmlParser') -> List[str]:
        def get_host_name(url: str) -> str:
            return url[7:].split('/')[0]

        def dfs(url: str):
            if url in visited:
                return

            visited.add(url)
            for next_url in htmlParser.getUrls(url):
                if get_host_name(url) == get_host_name(next_url):
                    dfs(next_url)

        visited = set()
        dfs(startUrl)
        return list(visited)
```

时间复杂度：O(n\*d) <br>
空间复杂度：O(n)

## follow up

[lintcode-234多线程网页爬虫](https://www.lintcode.com/problem/234/description)

```python
import threading
from collections import deque
import re

class Solution:
    pattern = re.compile(r"^https?://[^.]*.wikipedia.org")
    pool_size = 3
    pool = set()
    seen = set()
    tasks = deque([])
    results = []

    def crawler(self, url):
        self.tasks.append(url)
        self.seen.add(hash(url))
        while len(self.tasks) > 0:
            cur_url = self.tasks.popleft()
            if self.pattern.search(cur_url):
                self.results.append(cur_url)
                for next_url in HtmlHelper.parseUrls(cur_url):
                    t = threading.Thread(target=self._add_task, args=(next_url,))
                    t.start()
                    while True:
                        curts = threading.enumerate()
                        if (len(curts) < self.pool_size):
                            break
        return self.results

    def _add_task(self, url):
        docid = hash(url)
        if (docid not in self.seen):
            self.tasks.append(url)
            self.seen.add(docid)
```
